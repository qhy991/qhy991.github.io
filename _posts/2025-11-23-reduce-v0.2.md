---
layout: post
title: "CUDA Cooperative Groups: Deep Dive into Thread Hierarchy"
date: 2025-11-23
author: Haiyan Qin
tags: [CUDA, GPU, Cooperative Groups, Optimization, C++]
reading_time: 12
cover_image: /assets/blog-reduce-v02.png
excerpt: "A comprehensive guide to CUDA Cooperative Groups, explaining explicit synchronization, thread tiling, and how to use 'Russian Doll' style thread partitioning for efficient parallel algorithms."
---

# CUDA Cooperative Groups (协作组) 深度解析

## 1. 引言：为什么要引入 Cooperative Groups？

在 "Reduce 5" 的优化中，我们依赖了 `volatile` 关键字和 Warp 的隐式同步特性（Implicit Warp Synchronous Programming）。然而，随着 GPU 架构的发展（特别是 Volta 架构引入独立线程调度之后），这种隐式假设变得不再安全。

**Cooperative Groups (CG)** 是 CUDA 9.0 引入的新特性，它旨在：

1.  **显式化同步**：不再依赖“大家都执行到了这行代码”的隐式假设，而是通过对象明确控制同步。
2.  **灵活的层级**：允许开发者像“俄罗斯套娃”一样，将线程块切分成任意大小（如 32, 16, 8, 4）的子组，并在子组内安全通信。
3.  **代码复用**：编写一套模板代码，即可适应不同粒度的并行任务。

## 2. 完整可运行代码 (CUDA 11+, SM_70+)

这段代码演示了如何使用 CG 将一个线程块层层切分，并展示了线程在不同层级中的身份（Rank）变化。

```cpp
// cg_demo.cu
#include <stdio.h>
#include <cooperative_groups.h>

using namespace cooperative_groups;

// ---------- 设备端：打印一个 tile 的所有元信息 ----------
template <int T>
__device__ void
show_tile(const char *tag, thread_block_tile<T> p)
{
    // thread_rank(): 当前线程在本 tile 中的序号 (0 ~ T-1)
    int rank  = p.thread_rank();        
    // size(): 本 tile 的总线程数 (恒等于 T)
    int size  = p.size();               
    // meta_group_rank(): 本 tile 在父组中的序号
    int mrank = p.meta_group_rank();    
    // meta_group_size(): 父组中总共包含了多少个这样的 tile
    int msize = p.meta_group_size();    

    // 只让全局第 1234567 号线程打印，避免输出爆炸
    // 假设 gridDim足够大涵盖此线程
    auto grid = this_grid();
    if (grid.thread_rank() == 1234567) {     
        printf("%s rank in tile %2d size %2d  "
               "meta_rank %2d meta_size %2d  "
               "net_size %3d\n",
               tag, rank, size, mrank, msize, msize * size);
    }
}

// ---------- 全局内核：演示 5 级嵌套分区 ----------
__global__ void cgwarp(int gid)
{
    // 1. 获取整个网格和线程块句柄
    auto grid   = this_grid();
    auto block  = this_thread_block();

    // 2. 第一层切分：基于 Block 切分
    // 将 block 切分成 32 线程的 tile (即标准 Warp)
    auto warp32 = tiled_partition<32>(block);   
    // 将 block 切分成 16 线程的 tile (半 Warp)
    auto warp16 = tiled_partition<16>(block);   
    // 将 block 切分成 8 线程的 tile (1/4 Warp)
    auto warp8  = tiled_partition< 8>(block);   

    // 3. 第二层切分：基于 Warp 切分
    // 注意：这里是对 warp32 这个子组继续切分，而不是对 block 切分
    auto tile8  = tiled_partition< 8>(warp32);  
    // 4. 第三层切分：基于 Tile8 切分
    auto tile4  = tiled_partition< 4>(tile8);   

    if (grid.thread_rank() == gid) {
        printf("warps and sub-warps for thread %d:\n", gid);
        show_tile("warp32", warp32);
        show_tile("warp16", warp16);
        show_tile("warp8 ", warp8);
        show_tile("tile8 ", tile8);
        show_tile("tile4 ", tile4);
    }
}

// ---------- host ----------
int main(int argc, char *argv[])
{
    // 默认寻找第 1234567 号线程
    int gid     = (argc > 1) ? atoi(argv[1]) : 1234567;
    // 确保线程总数足够大
    int blocks  = 28800; 
    int threads = 256;

    printf("Target Thread GID: %d\n", gid);
    cgwarp<<<blocks, threads>>>(gid);
    cudaDeviceSynchronize();
    return 0;
}
```

### 预期输出与修正

假设目标线程全局 ID 为 `1234567`，BlockSize 为 `256`。

**计算坐标：**
*   `blockIdx` = 1234567 / 256 = 4822
*   `threadIdx` = 1234567 % 256 = 135

**正确的输出数值如下**（修正了部分书籍或旧版资料中的笔误）：

```text
warps and sub-warps for thread 1234567:
warp32 rank in tile  7 size 32  meta_rank  4 meta_size  8  net_size 256
warp16 rank in tile  7 size 16  meta_rank  8 meta_size 16  net_size 256
warp8  rank in tile  7 size  8  meta_rank 16 meta_size 32  net_size 256
tile8  rank in tile  7 size  8  meta_rank  0 meta_size  4  net_size  32
tile4  rank in tile  3 size  4  meta_rank  1 meta_size  2  net_size   8
```

## 3. 逐行解剖：为什么同一物理线程能拥有 5 套身份？

Cooperative Groups 允许我们从不同的**视角（View）**去看待同一个线程。就像一个人既是“公司的员工”，也是“开发组的组员”，还是“技术委员会的委员”。

### 1. `warp32` (标准 Warp)
*   **切分方式**：`tiled_partition<32>(block)`。将 256 人的 Block 切成 8 个 Warp。
*   **计算**：
    *   线程 135 在 Block 中的 Warp 编号 = 135 / 32 = **4** (`meta_rank`)。
    *   在 Warp 内的序号 = 135 % 32 = **7** (`rank`)。

### 2. `warp16` (半 Warp)
*   **切分方式**：`tiled_partition<16>(block)`。将 256 人的 Block 直接切成 16 个组。
*   **计算**：
    *   组编号 = 135 / 16 = **8** (`meta_rank`)。
    *   组内序号 = 135 % 16 = **7** (`rank`)。
    *   *(注：部分旧资料可能显示 14，通常是因为计算时使用了错误的线程 ID 或旧版 API 行为，标准行为应为 8)*。

### 3. `warp8` (1/4 Warp)
*   **切分方式**：`tiled_partition<8>(block)`。
*   **计算**：
    *   组编号 = 135 / 8 = **16** (`meta_rank`)。
    *   组内序号 = 135 % 8 = **7** (`rank`)。

### 4. `tile8` (Warp 内切分) - **关键点**
*   **切分方式**：`tiled_partition<8>(warp32)`。
*   **父子关系**：它的父组是 `warp32` (32人)，**而不是** `block` (256人)。
*   **计算**：
    *   线程 135 在其 `warp32` 中的序号是 7。
    *   将这个 32 人的小团体切成 4 个 8 人小组 (0~3)。
    *   序号 7 落在第 0 组：7 / 8 = **0** (`meta_rank`)。
    *   组内序号：7 % 8 = **7** (`rank`)。

### 5. `tile4` (Tile 内切分)
*   **切分方式**：`tiled_partition<4>(tile8)`。
*   **父子关系**：父组是 `tile8` (8人)。
*   **计算**：
    *   线程 135 在 `tile8` 中的序号是 7。
    *   将 8 人切成 2 个 4 人小组 (0, 1)。
    *   序号 7 落在第 1 组：7 / 4 = **1** (`meta_rank`)。
    *   组内序号：7 % 4 = **3** (`rank`)。

## 4. `warp8` 与 `tile8`：明明都是 8 线程，区别在哪？

这俩看起来都是“8个线程一组”，但在硬件调度和同步行为上有本质区别。

| 属性 | `warp8` (block 切分) | `tile8` (warp32 切分) |
| :--- | :--- | :--- |
| **父组 (Parent)** | 整个 `thread_block` (256线程) | 单个 `warp` (32线程) |
| **Meta Size** | 32 (256/8) | 4 (32/8) |
| **同步范围** | 可能跨 Warp (取决于 Block 大小和索引) | **严格在同一 Warp 内** |
| **同步代价** | 较高。编译器可能需要生成更重的同步指令 | **极低**。编译器直接优化为 `__syncwarp` 或空操作 |
| **Shuffle 支持** | **不支持** Warp Shuffle (因为无法保证同组线程在同一 Warp) | **支持** (因为必然在同一 Warp) |
| **典型用途** | 粗粒度任务分配，不涉及寄存器通信 | 精细的数学计算 (如 8点 FFT，4x4 矩阵乘) |

**结论**：如果你需要线程间交换数据 (Shuffle)，必须使用 `tile8` 这种基于 Warp 的切分。`warp8` 更多是逻辑上的分组。

## 5. 编译器在背后插入了哪些指令？

使用 `nvcc -arch=sm_70 -lineinfo -ptx -O3` 观察 PTX 汇编，你会发现 CG 的零开销魔法：

```cuda
// 对于 tile8 (子 Warp 切分)
// thread_rank(): 直接是个位运算
and.b32   %r1, %tid.x, 7;   // rank = tid & 7

// meta_group_rank(): 直接是位移
shr.b32   %r2, %tid.x, 3;   // meta = tid >> 3 (在 Warp 内)

// sync(): 
// 因为 8 线程完全在一条 Warp 里，且 SM_70+ 支持独立线程调度
// 编译器会插入轻量级的 bar.warp.sync 或利用掩码
bar.warp.sync 0xffffffff; 
```

**对比 block 切分：**
如果是 `tiled_partition<64>(block)`，由于跨了 Warp，编译器必须插入更重的 Barrier 指令：

```cuda
bar.sync 0, 64; 
```

且无法使用 Shuffle 指令进行通信。

## 6. 工程实践：这种“俄罗斯套娃”怎么用？

这种写法在高性能库（如 cuBLAS, cuFFT）开发中非常常见。

1.  **模板化编程 (Template Metaprogramming)**：你可以写一个通用的 reduce 函数，接受一个 Tile 对象。

    ```cpp
    template<typename Group>
    __device__ int reduce_sum(Group g, int val) {
        // 编译器自动根据 Group 大小展开循环
        for (int i = g.size() / 2; i > 0; i /= 2) {
            val += g.shfl_down(val, i);
        }
        return val;
    }
    ```

    这个函数可以被 `tile32`, `tile16`, `tile8` 任意调用，编译器会生成对应的高效机器码。

2.  **提高 Occupancy (占用率)**：假设你有一个小矩阵 4x4 需要计算。
    *   **旧方法**：用一个 Warp (32线程) 算，有 16 个线程在空转浪费。
    *   **新方法**：用 `tiled_partition<16>`，一个 Warp 可以同时处理 2 个矩阵，硬件利用率翻倍。

3.  **适配新硬件 (Tensor Cores)**：现代 GPU 的 Tensor Core 操作往往需要特定的线程组（如 32 线程或 128 线程 Warpgroup）。使用 CG 可以直接获取这些硬件所需的句柄，无缝对接 WMMA API。

## 总结

Cooperative Groups 让你拥有了**“上帝视角”**：你既可以掌控全局（Block），也可以微操细节（Sub-Warp Tile）。通过将线程块像乐高积木一样拆解，你可以在最合适的粒度上进行计算和同步，同时享受编译器带来的零开销优化。
